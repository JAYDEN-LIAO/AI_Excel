# backend/main.py
import os
import shutil
import uuid
import pandas as pd
from fastapi import FastAPI, UploadFile, File, Depends, HTTPException, Form
from fastapi.middleware.cors import CORSMiddleware
from sqlalchemy.orm import Session
from sqlalchemy import desc  # ğŸŸ¢ å¿…é¡»æ·»åŠ è¿™ä¸€è¡Œï¼
from pydantic import BaseModel
from typing import Union
from fastapi.responses import FileResponse
from urllib.parse import quote
from typing import List
from ai_service import get_multi_file_agent
#from formula_service import apply_multi_file_operation

# --- æœ¬åœ°æ¨¡å—å¼•å…¥ ---
from database import engine, Base, get_db
# ğŸŸ¢ å˜æ›´1ï¼šå¼•å…¥ FormulaTemplate æ¨¡å‹
from models import FileRecord, FormulaTemplate
from formula_service import apply_formula_to_file
# ç¡®ä¿ ai_service ä¸­è¿™ä¸¤ä¸ªå‡½æ•°éƒ½å­˜åœ¨
from ai_service import get_formula_suggestion, get_ai_analysis

# 1. è‡ªåŠ¨åˆ›å»ºæ•°æ®åº“è¡¨
# (è¿™ä¼šåŒæ—¶æ£€æŸ¥ file_records å’Œ formula_templates è¡¨æ˜¯å¦å­˜åœ¨)
Base.metadata.create_all(bind=engine)

app = FastAPI(title="Excelè‡ªåŠ¨åŒ–å¤„ç†ç³»ç»Ÿ")

# 2. é…ç½®è·¨åŸŸ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é…ç½®ä¸Šä¼ æ–‡ä»¶å¤¹
UPLOAD_DIR = "uploads"
if not os.path.exists(UPLOAD_DIR):
    os.makedirs(UPLOAD_DIR)

class MultiFileRequest(BaseModel):
    file_ids: List[int]  # ç”¨æˆ·é€‰ä¸­çš„å¤šä¸ªæ–‡ä»¶ ID
    query: str           # ç”¨æˆ·éœ€æ±‚ (ä¾‹å¦‚: "æŠŠè¡¨Aå’Œè¡¨BæŒ‰å·¥å·åˆå¹¶...")
# --- å®šä¹‰è¯·æ±‚æ¨¡å‹ ---
class ChatRequest(BaseModel):
    file_id: Union[str, int]
    query: str

class TemplateCreate(BaseModel):
    title: str
    description: str
    prompt_text: str
    category: str  # ğŸŸ¢ æ–°å¢å­—æ®µ

class TemplateUpdate(BaseModel):
    title: str
    description: str
    prompt_text: str
    category: str  # ğŸŸ¢ æ–°å¢å­—æ®µï¼Œå…è®¸ç¼–è¾‘æ—¶ä¿®æ”¹åˆ†ç±»

# --- æ¥å£å®šä¹‰ ---

@app.post("/api/process_multi_files")
def process_multi_files(request: MultiFileRequest, db: Session = Depends(get_db)):
    # A. æŸ¥å‡ºæ‰€æœ‰æ–‡ä»¶è®°å½•
    files = db.query(FileRecord).filter(FileRecord.id.in_(request.file_ids)).all()

    if len(files) < 1:
        raise HTTPException(status_code=400, detail="è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ–‡ä»¶")

    # B. å‡†å¤‡ä¸Šä¸‹æ–‡ï¼šè¯»å–æ‰€æœ‰æ–‡ä»¶åˆ°å†…å­˜å­—å…¸ 'dfs'
    loaded_dfs = {}
    file_map_for_ai = {} # ä»…ç”¨äºç»™ AI æä¾›é¢„è§ˆè·¯å¾„

    print(f"ğŸ”„ å¼€å§‹åŠ è½½ {len(files)} ä¸ªæ–‡ä»¶...")

    for f in files:
        if not os.path.exists(f.stored_path):
            continue
        try:
            # è¯»å–æ•°æ®
            df_temp = pd.read_excel(f.stored_path)
            # å­˜å…¥å­—å…¸
            loaded_dfs[f.filename] = df_temp
            # è®°å½•è·¯å¾„ä¾› AI é¢„è§ˆå‡½æ•°ä½¿ç”¨
            file_map_for_ai[f.filename] = f.stored_path
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶ {f.filename} å¤±è´¥: {e}")

    if not loaded_dfs:
        raise HTTPException(status_code=400, detail="æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨")

    try:
        # C. ç¬¬ä¸€æ­¥ï¼šæ‰¾ AI å†™ä»£ç 
        print(f"ğŸ¤– è¯·æ±‚ AI è¿›è¡Œå¤šè¡¨åˆ†æ: {list(loaded_dfs.keys())}")

        # è°ƒç”¨ AI (è¿™é‡Œ ai_service.py å·²ç»ä¿®æ”¹ä¸ºè¿”å›å­—å…¸)
        ai_result = get_multi_file_agent(file_map_for_ai, request.query)

        # ğŸŸ¢ã€å…³é”®ä¿®æ”¹ã€‘è§£æ AI è¿”å›çš„å­—å…¸
        column_formulas_data = {} # åˆå§‹åŒ–ä¸ºç©ºå­—å…¸

        if isinstance(ai_result, dict):
            py_code = ai_result.get("python_code", "")
            excel_formula_display = ai_result.get("excel_formula", "AI æœªæä¾›å…¬å¼é€»è¾‘")
            # æå–åˆ†åˆ—å…¬å¼
            column_formulas_data = ai_result.get("column_formulas", {})
        else:
            # å®¹é”™ï¼šå¦‚æœ ai_service æ²¡æ›´æ–°æˆ–è€…å‡ºé”™è¿”å›äº†å­—ç¬¦ä¸²
            py_code = str(ai_result)
            excel_formula_display = "å¤šè¡¨å¤æ‚è®¡ç®—"

        print(f"ğŸ AIç”Ÿæˆçš„ä»£ç :\n{py_code}")
        print(f"â— AIç”Ÿæˆçš„å…¬å¼é€»è¾‘: {excel_formula_display}")

        # D. ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œä»£ç 
        # å»ºç«‹æ²™ç®±ç¯å¢ƒ
        exec_globals = {
            'pd': pd,        # æ³¨å…¥ pandas
            'dfs': loaded_dfs, # ğŸŸ¢ æ³¨å…¥æ‰€æœ‰è¡¨æ•°æ®
            'result_df': None  # ç»“æœå ä½ç¬¦
        }

        # æ‰§è¡Œ AI ä»£ç 
        exec(py_code, exec_globals)

        # è·å–ç»“æœ
        final_df = exec_globals.get('result_df')

        if final_df is None or not isinstance(final_df, pd.DataFrame):
            raise Exception("ä»£ç æ‰§è¡Œå®Œæ¯•ï¼Œä½† `result_df` ä¸ºç©ºã€‚è¯·ç¡®ä¿ AI ä»£ç å°†ç»“æœèµ‹å€¼ç»™äº† `result_df`ã€‚")

        # E. ç¬¬ä¸‰æ­¥ï¼šç»“æœå­˜åº“
        new_filename = f"å¤šè¡¨è®¡ç®—ç»“æœ_{uuid.uuid4().hex[:6]}.xlsx"
        new_path = os.path.join(UPLOAD_DIR, new_filename)

        # ä¿å­˜ Excel
        final_df.to_excel(new_path, index=False)
        new_file_size = os.path.getsize(new_path)

        # å†™å…¥æ•°æ®åº“
        db_file = FileRecord(
            filename="å¤šè¡¨åˆå¹¶åˆ†æç»“æœ.xlsx",
            stored_path=new_path,
            file_size=new_file_size,
            status="processed",
            parent_id=files[0].id
        )
        db.add(db_file)
        db.commit()
        db.refresh(db_file)

        # ğŸŸ¢ã€å…³é”®ä¿®æ”¹ã€‘è¿”å›ç»“æ„å¢åŠ  raw_resultï¼Œé€‚é…å‰ç«¯å±•ç¤º
        return {
            "success": True,
            "msg": "å¤šè¡¨å¤„ç†æˆåŠŸ",
            "file_id": db_file.id,
            "download_url": f"/api/download/{new_filename}",
            "ai_code_used": py_code,
            # æ„é€ ä¸€ä¸ªå‰ç«¯èƒ½çœ‹æ‡‚çš„ result å¯¹è±¡ï¼Œç”¨äºæ˜¾ç¤ºåœ¨é»„è‰²æ¡†æ¡†é‡Œ
            "raw_result": {
                "action_type": "structure",
                "excel_formula": excel_formula_display, # è¿™é‡Œå°±æ˜¯é‚£ä¸²é•¿å…¬å¼
                "column_formulas": column_formulas_data, # ğŸ‘ˆ æ–°å¢ï¼šæŠŠåˆ†åˆ—å…¬å¼å­—å…¸ä¼ å›ç»™å‰ç«¯
                "explanation": f"å·²æ ¹æ®æŒ‡ä»¤åˆå¹¶ {len(files)} ä¸ªæ–‡ä»¶å¹¶è®¡ç®—ç»“æœã€‚",
                "target_position": "æ–°æ–‡ä»¶",
                "mode": "structure"
            }
        }

    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"success": False, "msg": f"å¤„ç†å¤±è´¥: {str(e)}"}
@app.get("/")
def read_root():
    return {"status": "ok", "message": "Backend is running!"}

# ==========================================
# ğŸŸ¢ æ–°å¢æ¥å£ï¼šè·å–å¯¹åº”å†å²è®°å½• (FilesPageç”¨)
# ==========================================
@app.get("/api/history")
def get_history_list(q: str = None, db: Session = Depends(get_db)):
    """
    è¿”å›æˆå¯¹çš„æ–‡ä»¶ç»“æ„ï¼š[{ original: {...}, result: {...} }]
    """
    # 1. æŸ¥è¯¢æ‰€æœ‰åŸå§‹æ–‡ä»¶ (parent_id ä¸º NULL)
    query = db.query(FileRecord).filter(FileRecord.parent_id == None)

    if q:
        query = query.filter(FileRecord.filename.contains(q))

    # æŒ‰æ—¶é—´å€’åº
    originals = query.order_by(desc(FileRecord.upload_time)).all()

    history_list = []

    for org in originals:
        # 2. æŸ¥æ‰¾è¯¥æ–‡ä»¶çš„æœ€æ–°ç”Ÿæˆçš„å­æ–‡ä»¶
        # è¿™é‡Œå‡è®¾ä¸€ä¸ªåŸæ–‡ä»¶å¯èƒ½å¯¹åº”å¤šä¸ªç»“æœï¼Œæˆ‘ä»¬åªå–æœ€æ–°çš„ä¸€ä¸ªï¼Œæˆ–è€…ä½ ä¹Ÿå¯ä»¥æ”¹ä¸ºè¿”å›åˆ—è¡¨
        child = db.query(FileRecord) \
            .filter(FileRecord.parent_id == org.id) \
            .order_by(desc(FileRecord.upload_time)) \
            .first()

        item = {
            "id": org.id, # å”¯ä¸€æ ‡è¯†
            "original": {
                "file_id": org.id,
                "filename": org.filename,
                "upload_time": org.upload_time.strftime("%Y-%m-%d %H:%M") if org.upload_time else ""
            },
            "result": None
        }

        if child:
            item["result"] = {
                "file_id": child.id,
                "filename": child.filename,
                "generated_time": child.upload_time.strftime("%Y-%m-%d %H:%M") if child.upload_time else "",
                # æ„é€ ä¸‹è½½é“¾æ¥
                "download_url": f"http://127.0.0.1:8000/api/download/{child.stored_path.split(os.sep)[-1]}"
            }

        history_list.append(item)

    return {
        "success": True,
        "data": history_list
    }

# ==========================================
# ğŸŸ¢ æ–°å¢æ¥å£ï¼šè·å–å…¬å¼æ¨¡æ¿åº“ (Section 0)
# ==========================================
@app.get("/api/templates")
def get_templates(db: Session = Depends(get_db)):
    """
    è·å–æ‰€æœ‰é¢„è®¾çš„ AI å…¬å¼æ¨¡æ¿
    """
    try:
        templates = db.query(FormulaTemplate).all()
        return {
            "success": True,
            "data": templates
        }
    except Exception as e:
        print(f"Error fetching templates: {e}")
        raise HTTPException(status_code=500, detail="è·å–æ¨¡æ¿å¤±è´¥")

# ==========================================
# ğŸŸ¢ æ–°å¢æ¥å£ï¼šæ›´æ–°å…¬å¼æ¨¡æ¿ (å·²ä¿®å¤ NameError)
# ==========================================
# ä¿®å¤ update_template ç»“å°¾è¢«æˆªæ–­çš„é—®é¢˜
@app.put("/api/templates/{template_id}")
def update_template(template_id: int, template_update: TemplateUpdate, db: Session = Depends(get_db)):
    # æŸ¥æ‰¾æ¨¡æ¿
    db_template = db.query(FormulaTemplate).filter(FormulaTemplate.id == template_id).first()

    if not db_template:
        raise HTTPException(status_code=404, detail="Template not found")

    # æ›´æ–°å­—æ®µ
    db_template.title = template_update.title
    db_template.description = template_update.description
    db_template.prompt_text = template_update.prompt_text
    db_template.category = template_update.category # è®°å¾—åŠ ä¸Šè¿™ä¸ª

    # æäº¤ä¿å­˜
    db.commit()
    db.refresh(db_template)
    return {"success": True, "data": db_template}
# ==========================================
# ğŸŸ¢ æ–°å¢æ¥å£ï¼šåˆ›å»ºæ–°æ¨¡æ¿
# ==========================================
@app.post("/api/templates")
def create_template(template: TemplateCreate, db: Session = Depends(get_db)):
    try:
        new_tpl = FormulaTemplate(
            title=template.title,
            description=template.description,
            prompt_text=template.prompt_text,
            category=template.category
        )
        db.add(new_tpl)
        db.commit()
        db.refresh(new_tpl)
        return {"success": True, "data": new_tpl}
    except Exception as e:
        print(f"Create Error: {e}")
        raise HTTPException(status_code=500, detail="åˆ›å»ºæ¨¡æ¿å¤±è´¥")

# ==========================================
# ğŸŸ¢ æ–°å¢æ¥å£ï¼šåˆ é™¤æ¨¡æ¿
# ==========================================
@app.delete("/api/templates/{template_id}")
def delete_template(template_id: int, db: Session = Depends(get_db)):
    tpl = db.query(FormulaTemplate).filter(FormulaTemplate.id == template_id).first()
    if not tpl:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°è¯¥æ¨¡æ¿")

    try:
        db.delete(tpl)
        db.commit()
        return {"success": True, "msg": "åˆ é™¤æˆåŠŸ"}
    except Exception as e:
        raise HTTPException(status_code=500, detail="åˆ é™¤å¤±è´¥")
    # æäº¤ä¿å­˜
    db.commit()
    db.refresh(db_template)
    return {"success": True, "data": db_template}

# ==========================================
# 1. æ–‡ä»¶ä¸Šä¼ æ¥å£
# ==========================================
@app.post("/api/upload")
async def upload_file(file: UploadFile = File(...), db: Session = Depends(get_db)):
    if not file.filename.endswith((".xlsx", ".xls")):
        raise HTTPException(status_code=400, detail="åªæ”¯æŒ Excel æ–‡ä»¶")

    # ç”Ÿæˆå®‰å…¨æ–‡ä»¶å
    file_ext = os.path.splitext(file.filename)[1]
    safe_filename = f"{uuid.uuid4().hex}{file_ext}"
    file_location = os.path.join(UPLOAD_DIR, safe_filename)

    # ä¿å­˜æ–‡ä»¶
    with open(file_location, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)

    file_size = os.path.getsize(file_location)

    # å­˜å…¥æ•°æ®åº“
    db_file = FileRecord(
        filename=file.filename,    # åŸå§‹æ–‡ä»¶å (æ˜¾ç¤ºç”¨)
        stored_path=file_location, # ç‰©ç†è·¯å¾„ (è¯»å–ç”¨)
        file_size=file_size,
        status="uploaded"
    )
    db.add(db_file)
    db.commit()
    db.refresh(db_file)

    return {"msg": "ä¸Šä¼ æˆåŠŸ", "file_id": db_file.id, "filename": db_file.filename}

# ==========================================
# ğŸŸ¢ æ–°å¢æ¥å£ï¼šè·å–æŒ‡å®šæ–‡ä»¶çš„é¢„è§ˆæ•°æ®
# ==========================================
# ==========================================
# ğŸŸ¢ ä¿®å¤åçš„æ¥å£ï¼šè·å–æŒ‡å®šæ–‡ä»¶çš„é¢„è§ˆæ•°æ®
# ==========================================
@app.get("/api/files/{file_id}/data")
def get_file_data(file_id: int, db: Session = Depends(get_db)):
    # 1. æ•°æ®åº“æŸ¥è¯¢æ–‡ä»¶è®°å½•
    file_record = db.query(FileRecord).filter(FileRecord.id == file_id).first()
    if not file_record:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    # 2. è·å–æ–‡ä»¶è·¯å¾„ (ğŸŸ¢ æ ¸å¿ƒä¿®å¤ï¼šä½¿ç”¨ stored_path)
    # models.py ä¸­å®šä¹‰çš„æ˜¯ stored_pathï¼Œä¸æ˜¯ file_path
    file_path = file_record.stored_path

    # å…¼å®¹æ€§/å®¹é”™å¤„ç†ï¼šæ£€æŸ¥ç‰©ç†æ–‡ä»¶
    if not os.path.exists(file_path):
        # å°è¯•åœ¨ uploads ç›®å½•ä¸‹æ‰¾
        potential_path = os.path.join(UPLOAD_DIR, os.path.basename(file_path))
        if os.path.exists(potential_path):
            file_path = potential_path
        else:
            print(f"DEBUG: æ•°æ®åº“è·¯å¾„: {file_record.stored_path}ï¼Œå®é™…æŸ¥æ‰¾è·¯å¾„: {file_path}")
            raise HTTPException(status_code=404, detail="ç£ç›˜ä¸Šæœªæ‰¾åˆ°è¯¥æ–‡ä»¶ï¼Œå¯èƒ½å·²è¢«åˆ é™¤")

    try:
        # 3. è¯»å– Excel (åªè¯»å–å‰ 50 è¡Œä»¥æé«˜é€Ÿåº¦)
        # keep_default_na=False å¯ä»¥é˜²æ­¢ pandas æŠŠç©ºå•å…ƒæ ¼è¯»æˆ NaN
        df = pd.read_excel(file_path, nrows=50)

        # 4. å†æ¬¡ç¡®ä¿å¤„ç†ç©ºå€¼ (JSON æ ‡å‡†ä¸æ”¯æŒ NaN)
        df = df.fillna("")

        # é’ˆå¯¹åŒ…å« "Timestamp" (æ—¥æœŸ) ç±»å‹çš„åˆ—è¿›è¡Œå­—ç¬¦ä¸²è½¬æ¢ï¼Œé˜²æ­¢ JSON åºåˆ—åŒ–æŠ¥é”™
        for col in df.columns:
            if pd.api.types.is_datetime64_any_dtype(df[col]):
                df[col] = df[col].astype(str)

        # 5. æ„é€  Ant Design Vue Table éœ€è¦çš„ columns æ ¼å¼
        columns = [
            {"title": col, "dataIndex": col, "key": col, "width": 150}
            for col in df.columns
        ]

        # 6. æ„é€ æ•°æ®åˆ—è¡¨
        data = df.to_dict(orient="records")

        return {
            "success": True,
            "filename": file_record.filename,
            "columns": columns,
            "data": data,
            "total_rows": 50 # åªæ˜¯é¢„è§ˆï¼Œæˆ–è€…ä½ å¯ä»¥å†è¯»ä¸€æ¬¡è·å– len(df)
        }

    except Exception as e:
        print(f"Read Excel Error: {e}")
        # æ‰“å°è¯¦ç»†å †æ ˆä»¥ä¾¿è°ƒè¯•
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
# ==========================================
# 2. è¯»å– Excel æ•°æ®æ¥å£ (ç”¨äºåˆå§‹åŠ è½½)
# ==========================================
# @app.get("/api/files/{file_id}/data")
# def get_file_data(file_id: str, db: Session = Depends(get_db)):
#     record = db.query(FileRecord).filter(FileRecord.id == file_id).first()
#     if not record:
#         raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
#
#     try:
#         df = pd.read_excel(record.stored_path)
#         # æ›¿æ¢ NaN ä¸ºç©ºå­—ç¬¦ä¸²ï¼Œé˜²æ­¢ JSON åºåˆ—åŒ–æŠ¥é”™
#         df = df.fillna("")
#
#         columns = [{"title": col, "dataIndex": col, "key": col, "width": 150} for col in df.columns]
#         data = df.head(20).to_dict(orient="records") # é™åˆ¶è¿”å›å‰20è¡Œ
#
#         return {
#             "filename": record.filename,
#             "columns": columns,
#             "data": data,
#             "total_rows": len(df)
#         }
#     except Exception as e:
#         print(f"Error reading excel: {e}")
#         raise HTTPException(status_code=500, detail=f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")

# ==========================================
# 3. çº¯ AI å¯¹è¯æ¥å£ (å’¨è¯¢ç”¨)
# ==========================================
@app.post("/api/chat")
def chat_with_data(request: ChatRequest, db: Session = Depends(get_db)):
    record = db.query(FileRecord).filter(FileRecord.id == request.file_id).first()
    if not record:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    # è°ƒç”¨ ai_service
    ai_result = get_ai_analysis(record.stored_path, request.query)

    # ğŸŸ¢ ä¿®å¤ï¼šai_service å·²ç»è¿”å›äº† {"answer": "..."}ï¼Œè¿™é‡Œç›´æ¥è¿”å› ai_result å³å¯
    # å¦‚æœ ai_service è¿”å›çš„æ˜¯çº¯å­—ç¬¦ä¸²ï¼Œåˆ™å°è£…ä¸€ä¸‹
    if isinstance(ai_result, dict):
        return ai_result
    else:
        return {"answer": ai_result}
# ==========================================
# 4. æ ¸å¿ƒï¼šæ™ºèƒ½æ“ä½œæ¥å£ (ç”Ÿæˆå…¬å¼/ä¿®æ”¹ç»“æ„)
# ==========================================
@app.post("/api/generate_formula")
def generate_excel_formula(request: ChatRequest, db: Session = Depends(get_db)):
    record = db.query(FileRecord).filter(FileRecord.id == request.file_id).first()
    if not record:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")

    ai_result = get_formula_suggestion(record.stored_path, request.query)

    if ai_result.get("action_type") == "error":
        return {"success": False, "msg": f"AI åˆ†æå¤±è´¥: {ai_result.get('explanation')}"}

    try:
        # æ‰§è¡Œç‰©ç†æ“ä½œ
        new_path, new_filename = apply_formula_to_file(record.stored_path, ai_result)

        # ğŸŸ¢ å…³é”®ä¿®æ”¹ï¼šå°†ç”Ÿæˆçš„æ–‡ä»¶å­˜å…¥æ•°æ®åº“ï¼Œå¹¶å…³è”çˆ¶ID
        new_file_size = os.path.getsize(new_path)
        db_child_file = FileRecord(
            filename=f"å¤„ç†ç»“æœ_{record.filename}", # æˆ–è€…ä½¿ç”¨ new_filename
            stored_path=new_path,
            file_size=new_file_size,
            status="processed",
            parent_id=record.id  # ğŸŸ¢ å»ºç«‹å…³è”ï¼
        )
        db.add(db_child_file)
        db.commit()
        db.refresh(db_child_file)

        # é¢„è§ˆé€»è¾‘ (ä¿æŒä¸å˜)
        df_new = pd.read_excel(new_path)
        preview_df = df_new.head(50).fillna("")
        preview_columns = [{"title": col, "dataIndex": col, "key": col, "width": 100} for col in preview_df.columns]
        preview_rows = preview_df.to_dict(orient='records')

        return {
            "success": True,
            "msg": "å¤„ç†æˆåŠŸ",
            "download_url": f"/api/download/{os.path.basename(new_path)}", # ç®€åŒ–è·¯å¾„
            "file_id": db_child_file.id, # è¿”å›æ–°çš„ ID
            "raw_result": ai_result,
            "preview_data": {
                "columns": preview_columns,
                "dataSource": preview_rows
            }
        }

    except Exception as e:
        print(f"Process Error: {str(e)}")
        return {"success": False, "msg": f"æ‰§è¡Œå¤±è´¥: {str(e)}"}

# ==========================================
# 5. æ–‡ä»¶ä¸‹è½½æ¥å£
# ==========================================
@app.get("/api/download/{filename}")
def download_file(filename: str):
    file_path = os.path.join(UPLOAD_DIR, filename)
    if os.path.exists(file_path):
        return FileResponse(
            file_path,
            media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            filename=filename # å»ºè®®æ­¤å¤„ç»“åˆæ•°æ®åº“æŸ¥çœŸå®æ–‡ä»¶åï¼Œè¿™é‡Œæš‚ä¸”ç”¨ç‰©ç†æ–‡ä»¶å
        )
    return {"error": "File not found"}

# ==========================================
# ğŸŸ¢ æ–°å¢æ¥å£ï¼šæ™ºèƒ½æ‰¹é‡ä¸Šä¼  (æ”¯æŒ åˆå¹¶æ¨¡å¼/ç‹¬ç«‹æ¨¡å¼)
# ==========================================
@app.post("/api/upload/batch")
async def batch_upload_files(
        files: List[UploadFile] = File(...),
        auto_merge: bool = Form(False),  # ğŸŸ¢ å¼€å…³ï¼šTrue=åˆå¹¶ä¸ºä¸€ä¸ª, False=ä¿æŒç‹¬ç«‹
        db: Session = Depends(get_db)
):
    """
    æ‰¹é‡ä¸Šä¼ æ¥å£ï¼š
    - auto_merge=True: å¼ºæ ¡éªŒåˆ—åï¼Œåˆå¹¶ä¸ºä¸€ä¸ªæ–°æ–‡ä»¶ï¼Œè¿”å› 1 ä¸ª file_idã€‚
    - auto_merge=False: å¼±æ ¡éªŒï¼Œä¿å­˜æ‰€æœ‰æ–‡ä»¶ï¼Œè¿”å› N ä¸ª file_id åˆ—è¡¨ã€‚
    """
    if not files or len(files) == 0:
        raise HTTPException(status_code=400, detail="æœªä¸Šä¼ ä»»ä½•æ–‡ä»¶")

    uploaded_records = [] # åªæœ‰ç‹¬ç«‹æ¨¡å¼ä¼šç”¨åˆ°
    dfs_to_merge = []     # åªæœ‰åˆå¹¶æ¨¡å¼ä¼šç”¨åˆ°
    base_columns = None   # ç”¨äºåˆå¹¶æ¨¡å¼çš„åˆ—åæ ¡éªŒ

    # --- 1. å¾ªç¯å¤„ç†æ‰€æœ‰æ–‡ä»¶ ---
    for file in files:
        if not file.filename.endswith((".xlsx", ".xls")):
            raise HTTPException(status_code=400, detail=f"æ–‡ä»¶ {file.filename} æ ¼å¼é”™è¯¯ï¼Œä»…æ”¯æŒ Excel")

        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            content = await file.read()
            df = pd.read_excel(content)

            # [é€šç”¨éªŒè¯]ï¼šç©ºè¡¨æ£€æŸ¥
            if df.empty:
                raise HTTPException(status_code=400, detail=f"æ–‡ä»¶ {file.filename} æ˜¯ç©ºçš„ï¼Œæ— æ³•å¤„ç†")

            # --- åˆ†æ”¯é€»è¾‘ ---
            if auto_merge:
                # [åˆå¹¶æ¨¡å¼]ï¼šä¸¥æ ¼æ ¡éªŒåˆ—åä¸€è‡´æ€§
                current_columns = list(df.columns)
                if base_columns is None:
                    base_columns = current_columns
                else:
                    if set(base_columns) != set(current_columns):
                        raise HTTPException(
                            status_code=400,
                            detail=f"ã€åˆå¹¶å¤±è´¥ã€‘æ–‡ä»¶ '{file.filename}' çš„åˆ—åä¸å…¶ä»–æ–‡ä»¶ä¸ä¸€è‡´ã€‚\né¢„æœŸ: {base_columns}\nå®é™…: {current_columns}"
                        )

                # è®°å½•æ¥æºï¼Œå‡†å¤‡åˆå¹¶
                df['_æ¥æºæ–‡ä»¶'] = file.filename
                dfs_to_merge.append(df)

            else:
                # [ç‹¬ç«‹æ¨¡å¼]ï¼šç›´æ¥ä¿å­˜æ¯ä¸ªæ–‡ä»¶
                # 1. ä¿å­˜ç‰©ç†æ–‡ä»¶
                file_ext = os.path.splitext(file.filename)[1]
                safe_filename = f"{uuid.uuid4().hex}{file_ext}"
                save_path = os.path.join(UPLOAD_DIR, safe_filename)

                # ç”±äº content å·²ç»è¢« read() è¯»åˆ°å†…å­˜ï¼Œæˆ‘ä»¬éœ€è¦ç”¨ pandas å†å†™å‡ºï¼Œæˆ–è€…é‡ç½®æŒ‡é’ˆ
                # ç®€å•èµ·è§ï¼Œç›´æ¥ç”¨ pandas å†™å‡ºï¼ˆé¡ºä¾¿è¿˜èƒ½æ ‡å‡†åŒ–æ ¼å¼ï¼‰
                df.to_excel(save_path, index=False)
                file_size = os.path.getsize(save_path)

                # 2. å­˜å…¥æ•°æ®åº“
                db_file = FileRecord(
                    filename=file.filename,
                    stored_path=save_path,
                    file_size=file_size,
                    status="uploaded"
                )
                db.add(db_file)
                db.commit()
                db.refresh(db_file)

                # æ·»åŠ åˆ°è¿”å›åˆ—è¡¨
                uploaded_records.append({
                    "file_id": db_file.id,
                    "filename": db_file.filename
                })

        except HTTPException as he:
            raise he
        except Exception as e:
            print(f"Error processing {file.filename}: {e}")
            raise HTTPException(status_code=500, detail=f"å¤„ç†æ–‡ä»¶ {file.filename} å¤±è´¥: {str(e)}")

    # --- 2. åç»­å¤„ç† (é’ˆå¯¹åˆå¹¶æ¨¡å¼) ---
    if auto_merge:
        try:
            # æ‰§è¡Œåˆå¹¶
            final_df = pd.concat(dfs_to_merge, ignore_index=True)

            # ä¿å­˜åˆå¹¶åçš„æ–‡ä»¶
            merged_filename = f"merged_{uuid.uuid4().hex[:8]}.xlsx"
            save_path = os.path.join(UPLOAD_DIR, merged_filename)
            final_df.to_excel(save_path, index=False)

            # å­˜åº“
            display_name = f"æ‰¹é‡åˆå¹¶_{len(files)}ä¸ªæ–‡ä»¶.xlsx"
            db_file = FileRecord(
                filename=display_name,
                stored_path=save_path,
                file_size=os.path.getsize(save_path),
                status="uploaded"
            )
            db.add(db_file)
            db.commit()
            db.refresh(db_file)

            return {
                "mode": "merge",
                "success": True,
                "msg": f"æˆåŠŸåˆå¹¶ {len(files)} ä¸ªæ–‡ä»¶",
                "file_info": {
                    "file_id": db_file.id,
                    "filename": db_file.filename,
                    "total_rows": len(final_df)
                }
            }

        except Exception as e:
            raise HTTPException(status_code=500, detail=f"åˆå¹¶è¿‡ç¨‹å‡ºé”™: {str(e)}")

    # --- 3. åç»­å¤„ç† (é’ˆå¯¹ç‹¬ç«‹æ¨¡å¼) ---
    else:
        return {
            "mode": "independent",
            "success": True,
            "msg": f"æˆåŠŸä¸Šä¼  {len(uploaded_records)} ä¸ªæ–‡ä»¶",
            "files": uploaded_records # è¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«æ‰€æœ‰ID
        }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="127.0.0.1", port=8000, reload=True)